# Forecasting configuration (skeleton)
seed: 42
base_currency: "USD"
universe:
  - SPY
  - QQQ
  - AGG
horizon_days: 20
features:
  price:
    returns_windows: [5, 20, 60]
    vol_windows: [20, 60]
    momentum_windows: [20, 60, 120]
  regimes:
    use_vix: true
cv:
  scheme: "expanding"
  n_folds: 5
  embargo_days: 5
model:
  early_stopping_rounds: 50
  params:
    n_estimators: 835
    learning_rate: 0.043155591977342846
    max_depth: 3
    subsample: 0.708617135873426
    colsample_bytree: 0.6503551765398999
    min_child_weight: 9
    reg_alpha: 0.04965951682058345
    reg_lambda: 1.7209704724874504
seed: 42
artifacts_dir: "artifacts/forecaster"
tuning:
  enabled: false
  method: random
  n_trials: 120                 # try 120 to 200 initially
  tickers:                      # calibrate across the whole domain
    [SPY, QQQ, AGG, BND, HYG, EMB, VWOB, EWY, IWM, VWO, IEMG, CMOD.L, GSG, GLD, RWO, IFGL, 148070.KS, 385560.KS, 278530.KS]
  early_stopping_rounds: 50
  min_history_days: 120
  seed: 42
  aggregation:
      unit: nrmse                 # scales error by each tickerâ€™s target std
      weight: equal               # equal weight per ticker (or 'n_obs' if you prefer)
      reducer: mean               # mean (keep it simple and robust)

  search_space:
    n_estimators: [300, 1200]
    learning_rate: [0.03, 0.12]
    max_depth: {"low": 3, "high": 7, "type": "int"}
    subsample: [0.6, 0.95]
    colsample_bytree: [0.6, 0.95]
    min_child_weight: {"low": 1, "high": 10, "type": "int"}
    reg_lambda: [0.8, 1.8]
    reg_alpha: [0.0, 0.3]